{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1147594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "source = \"I am a boy.\"\n",
    "target = \"Ich bin ein Junge.\"\n",
    "\n",
    "# ----------\n",
    "# Encoder[\"I am a boy.\"] -> hidden state (context vector)\n",
    "# Next Token Prediction\n",
    "# 1. step Decoder[hidden state, \"<bos>\"] -> \"ich\"\n",
    "# 2. step Decoder[hidden state, (\"<bos>\", \"ich\") ] -> \"bin\" \n",
    "# 3. step Decoder[hidden state, (\"<bos>\", \"ich\", \"bin\") ] -> \"ein\" \n",
    "# 4. step Decoder[hidden state, (\"<bos>\", \"ich\", \"bin\", \"ein\") ] -> \"Junge\"\n",
    "# 5. step Decoder[hidden state, (\"<bos>\", \"ich\", \"bin\", \"ein\", \"Junge\") ] -> \".\" \n",
    "# 6. step Decoder[hidden state, (\"<bos>\", \"ich\", \"bin\", \"ein\", \"Junge\", \".\") ] -> \"<eos>\" \n",
    "\n",
    "# X = (hidden state, (\"<bos>\", \"ich\", \"bin\", \"ein\", \"Junge\", \".\"))\n",
    "# y = (\"ich\", \"bin\", \"ein\", \"Junge\", \".\", \"<eos>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7087ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path = \"./deu.txt\"\n",
    "\n",
    "lines = open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "lines = lines[:20000]\n",
    "\n",
    "pairs = [ln.split(\"\\t\")[:2] for ln in lines] \n",
    "src_texts, tgt_texts = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, UNK, BOS, EOS = 0, 1, 2, 3\n",
    "\n",
    "VOCAB_SIZE = 20004 \n",
    "\n",
    "def tokenize(s): return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "def build_vocab(texts, max_tokens=VOCAB_SIZE):\n",
    "    from collections import Counter\n",
    "    freq = Counter(tok for t in texts for tok in tokenize(t))\n",
    "    itos = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"] + [w for w,_ in freq.most_common(max_tokens-4)]\n",
    "    return {w:i for i,w in enumerate(itos)}, itos\n",
    "src_texts_vocab, src_itos = build_vocab(src_texts)\n",
    "tgt_texts_vocab, tgt_itos = build_vocab(tgt_texts)\n",
    "\n",
    "\n",
    "def vectorize(text, stoi, max_len, add_bos_eos=False):\n",
    "    ids = [stoi.get(tok, UNK) for tok in tokenize(text)]\n",
    "    if add_bos_eos: ids = [BOS] + ids + [EOS]\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len: ids += [PAD]*(max_len-len(ids))\n",
    "    return ids\n",
    "\n",
    "max_src, max_tgt = 30, 30 \n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src = torch.tensor([vectorize(t, src_texts_vocab, max_src) for t in src_batch])\n",
    "    tgt = torch.tensor([vectorize(t, tgt_texts_vocab, max_tgt, add_bos_eos=True) for t in tgt_batch])\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "dataset = list(zip(src_texts, tgt_texts))\n",
    "loader = DataLoader(dataset, batch_size= 64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83d07efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're in luck.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_texts[13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize(src_texts[13000], src_texts_vocab, max_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb74cf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 0, 'for': 1, 'is': 2, 'sample': 3, 'sentence': 4, 'this': 5}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is sample sentence for embedding\"\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "611b6164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2410, -0.7009, -1.0035],\n",
       "        [ 0.0272, -0.7268, -0.5822],\n",
       "        [ 0.6845, -0.2334,  0.2144],\n",
       "        [ 1.4403,  1.0988, -1.7053],\n",
       "        [ 0.9302,  1.7344, -0.6735],\n",
       "        [-0.1064, -2.0549, -0.6539]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_tmp = len(dc)\n",
    "emb = torch.nn.Embedding(vocab_size_tmp, 3)\n",
    "emb.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe4a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128 # in practice starts from 768 \n",
    "hid_dim = 256 \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, vocab_size) # classifier head, mlp head, FFNN head \n",
    "    \n",
    "    def forward(self, x, h): # hidden state from encoder\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x,h) # use h from encoder in the decoder\n",
    "        return self.fc(out) # decision which token likely the next\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, src, tgt_in_dec):\n",
    "        # src ... english sentences\n",
    "        # tgt_in ...  already translated part german sentences \n",
    "        hidden_enc = self.enc(src)\n",
    "        logits = self.dec(tgt_in_dec, hidden_enc)\n",
    "        return logits \n",
    "\n",
    "device = \"mps\" # you use \"cpu\" or \"cuda\"\n",
    "\n",
    "model = Seq2Seq(\n",
    "    Encoder(len(src_texts_vocab)),\n",
    "    Decoder(len(tgt_texts_vocab)),   \n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eb23e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4.4610\n",
      "ich bin ein\n",
      "epoch 2: loss 3.3501\n",
      "ich habe das gesagt\n",
      "epoch 3: loss 2.7508\n",
      "ich habe einen hund\n",
      "epoch 4: loss 2.3282\n",
      "ich werde es versuchen\n",
      "epoch 5: loss 2.0096\n",
      "ich werde mich drum kÃ¼mmern\n",
      "epoch 6: loss 1.7556\n",
      "ich werde mein bestes holen\n",
      "epoch 7: loss 1.5233\n",
      "ich werde mein bestes tun\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m src, tgt_in, tgt_out \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     24\u001b[39m     src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtgt_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     loss = crit(logits.reshape(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)), tgt_out.reshape(-\u001b[32m1\u001b[39m)) \n\u001b[32m     27\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mSeq2Seq.forward\u001b[39m\u001b[34m(self, src, tgt_in_dec)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt_in_dec):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# src ... english sentences\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# tgt_in ...  already translated part german sentences \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     hidden_enc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.dec(tgt_in_dec, hidden_enc)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m     11\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     _, hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/SRH_university/ML_mechatronics/WS2026_2/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1415\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1413\u001b[39m \u001b[38;5;28mself\u001b[39m.check_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1415\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     result = _VF.gru(\n\u001b[32m   1428\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1429\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1436\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1437\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "crit = nn.CrossEntropyLoss(ignore_index=PAD) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "epochs = 20\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate(prompt, max_len=max_tgt):\n",
    "    model.eval()\n",
    "    src = torch.tensor([vectorize(prompt, src_texts_vocab, max_src)], device=device)\n",
    "    h = model.enc(src)\n",
    "    ys = torch.tensor([[BOS]], device=device)\n",
    "    out_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        logits = model.dec(ys, h)\n",
    "        next_id = logits[0, -1].argmax().item()\n",
    "        if next_id in (EOS, PAD): break\n",
    "        out_tokens.append(next_id)\n",
    "        ys = torch.cat([ys, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return \" \".join(tgt_itos[t] for t in out_tokens)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0 \n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src,tgt_in)\n",
    "        loss = crit(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1)) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # gradient clipping ->  preventing exploding gradient \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"epoch {epoch+1}: loss {running_loss/len(loader):.4f}\") # \n",
    "    print(translate(\"I will do my best.\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
