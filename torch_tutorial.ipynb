{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "60d0f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.10.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.10.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d2b640b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor([1,2,3]) # n-dimensional array (similar to numpy)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5d91bef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2438, 0.1922, 0.6897],\n",
       "        [0.2417, 0.7114, 0.3537]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2,3) # random numbers (2 rows, 3 columns)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5885f910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(2,3)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "92bf0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(2,3)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "358e3c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + ones_tensor # addition with broadcasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5d34cf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "a = torch.tensor([[1.,2],[3,4]])\n",
    "b = torch.tensor([[5.,6],[7,8]])\n",
    "\n",
    "a @ b # or torch.matmul(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d1973367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b # elementwise \n",
    "a.sum() # sum\n",
    "a.mean() # mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2bdebd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu, cuda, mps and possible \n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6ad571fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradients \n",
    "\n",
    "x = torch.tensor(2., requires_grad=True) # mode: propagate the gradients over all computation steps\n",
    "y = x**2 + 3*x +5\n",
    "# 2*x + 3 -> 2*2.0 +3 = 7\n",
    "y.backward() # compute gradients using backpropagation algorithm \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13af9b",
   "metadata": {},
   "source": [
    "# simple NN and one gradient step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9fce2670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.95 (before update)\n",
      "Loss: 0.78 (after update)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # Neural Networks\n",
    "import torch.optim as optim # optimizer framework for gradient methods \n",
    "\n",
    "# 10 inputs, 1 output -> fully connected feed-forward neural network \n",
    "NN = nn.Linear(10,1) # W*x +b, in Tensorflow -> Dense \n",
    "# MLP -> Multi-Layer Perceptron \n",
    "# in Literature/Publication: FC, FFN, FFNN, MLP \n",
    "\n",
    "loss = nn.MSELoss() # mean squared error\n",
    "# loss, cost, criterion, crit \n",
    "optimizer = optim.SGD(NN.parameters(), lr = 1e-2)\n",
    "# lr = learning rate, eta, alpha \n",
    "# NN.parameters() ... weights and biases \n",
    "\n",
    "input_data = torch.rand(10) # random data, X\n",
    "output = NN(input_data) # y_pred, predictions, y_hat\n",
    "y = torch.ones(1) # ground truth, label, target, regr \n",
    "\n",
    "# initial value of the loss function \n",
    "loss_output = loss(y, output) # Difference between reality (y) and expectation (output)\n",
    "print(f\"Loss: {loss_output:.2f} (before update)\")\n",
    "\n",
    "# two magical lines \n",
    "loss_output.backward() # compute gradients \n",
    "optimizer.step() # Update weights and biases \n",
    "\n",
    "output_new = NN(input_data) # here are new weights and biases \n",
    "loss_new = loss(output_new, y) # value of the loss function after the update\n",
    "print(f\"Loss: {loss_new:.2f} (after update)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3674e7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0269], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output # initial output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "77f6a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1163], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907dfb91",
   "metadata": {},
   "source": [
    "# FashionMNIST Dataset\n",
    "modern HelloWorld for deep NNs (by Zalando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ce2e00f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3205))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precalculation of mean and std for FashioMNIST (training set)\n",
    "from torchvision import datasets, transforms\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0 \n",
    "num_samples = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    images = images.view(images.size(0),-1) # better \n",
    "    mean += images.mean(dim=1).sum()\n",
    "    std += images.std(dim=1).sum()\n",
    "    num_samples += images.size(0) # number of images\n",
    "\n",
    "mean /= num_samples\n",
    "std /= num_samples\n",
    "mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1203b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert to tensor,\n",
    "    transforms.Normalize((0.2860,), (0.3530,)), # mean, standard deviation  (x - mean) / std for each image x \n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Data Augmentation \n",
    "    transforms.RandomAffine(\n",
    "        degrees=10,\n",
    "        translate=(0.05, 0.05),\n",
    "        scale=(0.95, 1.05)\n",
    "    ),\n",
    "]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c95a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100480"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*128 +128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "75f0fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "\n",
    "class NN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__() # init from the superclass\n",
    "        self.layer1 = nn.Linear(28*28, 128 ) # 28x28 pixel pictures\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.layer2 = nn.Linear(128, 64) # hidden layer \n",
    "        self.bn2 = nn.BatchNorm1d(64) \n",
    "        self.layer3 = nn.Linear(64, 10) # output lyaer, 10 = number of product categories \n",
    "        self.drop = nn.Dropout(0.3) # 30 % of activations are set to zero \n",
    "        # 0.1 -> 0.2 ... -> 0.5 \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D \n",
    "        x = torch.relu(self.bn1(self.layer1(x)))  # before activation BatchNorm\n",
    "        x = self.drop(x)\n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.drop(x) # here dropout is usually placed  \n",
    "        x = self.layer3(x) # identity activation -> logit (Pytorch optimization) \n",
    "        # there is no need to compute gradients of softmax \n",
    "        return x\n",
    "    # alternative \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D \n",
    "        x = torch.relu(self.layer1(x))  # after activation BatchNorm\n",
    "        x = self.bn1(x)\n",
    "        x = self.drop(x)\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.drop(x) # here dropout is usually placed  \n",
    "        x = self.layer3(x) # identity activation -> logit (Pytorch optimization) \n",
    "        # there is no need to compute gradients of softmax \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "eebb89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 40], Loss: 1398.2091064453125\n",
      "Epoch[2 / 40], Loss: 1009.6746826171875\n",
      "Epoch[3 / 40], Loss: 889.46533203125\n",
      "Epoch[4 / 40], Loss: 825.4232788085938\n",
      "Epoch[5 / 40], Loss: 782.2587280273438\n",
      "Epoch[6 / 40], Loss: 751.6229858398438\n",
      "Epoch[7 / 40], Loss: 730.1636962890625\n",
      "Epoch[8 / 40], Loss: 712.046630859375\n",
      "Epoch[9 / 40], Loss: 695.0664672851562\n",
      "Epoch[10 / 40], Loss: 681.6971435546875\n",
      "Epoch[11 / 40], Loss: 672.7581176757812\n",
      "Epoch[12 / 40], Loss: 666.9666748046875\n",
      "Epoch[13 / 40], Loss: 656.494873046875\n",
      "Epoch[14 / 40], Loss: 648.0926513671875\n",
      "Epoch[15 / 40], Loss: 640.3860473632812\n",
      "Epoch[16 / 40], Loss: 637.568359375\n",
      "Epoch[17 / 40], Loss: 627.7593383789062\n",
      "Epoch[18 / 40], Loss: 624.2337036132812\n",
      "Epoch[19 / 40], Loss: 619.9874267578125\n",
      "Epoch[20 / 40], Loss: 611.7109985351562\n",
      "Epoch[21 / 40], Loss: 614.1640014648438\n",
      "Epoch[22 / 40], Loss: 604.67724609375\n",
      "Epoch[23 / 40], Loss: 600.8709106445312\n",
      "Epoch[24 / 40], Loss: 599.1452026367188\n",
      "Epoch[25 / 40], Loss: 593.6200561523438\n",
      "Epoch[26 / 40], Loss: 592.0222778320312\n",
      "Epoch[27 / 40], Loss: 587.53271484375\n",
      "Epoch[28 / 40], Loss: 584.6994018554688\n",
      "Epoch[29 / 40], Loss: 582.3880004882812\n",
      "Epoch[30 / 40], Loss: 579.2684936523438\n",
      "Epoch[31 / 40], Loss: 575.8483276367188\n",
      "Epoch[32 / 40], Loss: 573.4174194335938\n",
      "Epoch[33 / 40], Loss: 570.9223022460938\n",
      "Epoch[34 / 40], Loss: 569.7086181640625\n",
      "Epoch[35 / 40], Loss: 566.299072265625\n",
      "Epoch[36 / 40], Loss: 565.6846313476562\n",
      "Epoch[37 / 40], Loss: 561.4033203125\n",
      "Epoch[38 / 40], Loss: 561.3253784179688\n",
      "Epoch[39 / 40], Loss: 555.5181274414062\n",
      "Epoch[40 / 40], Loss: 556.700927734375\n"
     ]
    }
   ],
   "source": [
    "# Now training\n",
    "\n",
    "model = NN()\n",
    "lr = 1e-3 # learning rate\n",
    "loss = nn.CrossEntropyLoss() # because multi-class problem\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 40\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # training mode \n",
    "    running_loss = 0.0 # loss per epoch \n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # reset the gradient \n",
    "        # forward step \n",
    "        outputs = model(images) # propagate the images\n",
    "        curr_loss = loss(outputs, labels) \n",
    "        running_loss += curr_loss\n",
    "        # backward\n",
    "        curr_loss.backward() # gradients\n",
    "        optimizer.step() # update weights and biases\n",
    "    \n",
    "    print(f\"Epoch[{epoch +1} / {n_epochs}], Loss: {running_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "860caa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) # size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6048f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset) # size of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7d515313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "\n",
    "\n",
    "model.eval() # setting the model to evaluation mode (implementation optimization)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # we are not interested in gradient anymore \n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images) # logits\n",
    "        predicted = torch.max(outputs.data, 1)[-1] # argmax-> at which class we have maximum logit \n",
    "        total += labels.size(0) \n",
    "        correct += (predicted==labels).sum().item()\n",
    "\n",
    "accuracy = correct/total\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
